{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note of Hands-on ML with Scikit-Learn & TensorFlow by Lei Fu\n",
    "\n",
    "## Chapter 1. The Machine Learning Landscape\n",
    "\n",
    "Early specialized applications, e.g. Optical Character Recognition (OCR). Became main stream in 1990s: _spam filter_.\n",
    "\n",
    "### What Is Machine Learning?\n",
    "\n",
    "Machine\tLearning is\tthe\tscience\t(and art) of programming computers so they can _learn_ from data.\n",
    "\n",
    "Machine\tLearning is the\tfield of study that gives computers\tthe\tability\tto learn without being explicitly programmed.\n",
    "<div style=\"text-align: right\"> - Arthur Samuel, 1959 </div> \n",
    "\n",
    "A computer program is said to learn\tfrom experience\tE with respect to some task T and some performance measure P, if\tits\tperformance\ton T, as measured by P, improves with experience E.\n",
    "<div style=\"text-align: right\"> - Tom Mitchell, 1997 </div> \n",
    "\n",
    "training set, training instance (sample), accuracy\n",
    "\n",
    "### Why Use Machine Learning \n",
    "\n",
    "<div style=\"width:600 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig1-1.png\" width=600px alt=\"fig1-1\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 1-1. The traditional approach_</div>\n",
    "\n",
    "<div style=\"width:600 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig1-2.png\" width=600px alt=\"fig1-2\" style=\"padding-bottom:1.0em;padding-top:2.0em;\"></center>_Figure 1-2. Machine Learning approach_</div>\n",
    "\n",
    "<div style=\"width:600 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig1-3.png\" width=600px alt=\"fig1-3\" style=\"padding-bottom:1.0em;padding-top:2.0em\"></center>_Figure 1-3. Automatically adapting to change_</div>\n",
    "\n",
    "<div style=\"width:600 px; font-size:100%; text-align:center;\"> <center><img src=\"img/fig1-4.png\" width=600px alt=\"fig1-4\" style=\"padding-bottom:1.0em;padding-top:2.0em\"></center>_Figure 1-4. Machine learning can help humans learning_</div>\n",
    "\n",
    "Machine\tLearning is great for:\n",
    "1. Problems\tfor which existing solutions require a lot of hand-tuning or long lists of rules: one Machine Learning algorithm can often simplify code and perform better (shorter, easier to maintain, accurate).\n",
    "2. Complex problems for traditional approaches or have no known algorithm (speech recognition).\n",
    "3. Fluctuating environments: a Machine Learning\tsystem can adapt to new data.\n",
    "4. Help humans learning. Getting insights about complex problems and large amounts of data.\n",
    "\n",
    "### Types of Machine Learning Systems\n",
    "\n",
    "Amount and type of human supervision:\n",
    "1. supervised\n",
    "2. unsupervised\n",
    "3. semisupervised\n",
    "4. reinforcement learning\n",
    "<br>\n",
    "\n",
    "Whether or not they can learn incrementally on the fly:\n",
    "1. online\n",
    "2. batch learning\n",
    "\n",
    "Whether they work by simply comparing new data points to known data points, or instead detect patterns in the training data and build a predictive model:\n",
    "1. instance-based\n",
    "2. model-based\n",
    "\n",
    "__Supervised Learning__\n",
    "\n",
    "Label: desired solution\n",
    "\n",
    "Classification/regression, predictors. \n",
    "<br>\n",
    "_Logistic Regression_: regression algorithm sued for classification. \n",
    "<br>\n",
    "Attribute: a data type; Feature: attribute + its value\n",
    "\n",
    "Supervised learning algorithms:\n",
    "1. k-Nearest Neighbors\n",
    "2. Linear Regression\n",
    "3. Logistic Regression\n",
    "4. Support Vector Machines (SVM)\n",
    "5. Decision Tress and Random Forests\n",
    "6. Neural networks\n",
    "\n",
    "__Unsupervised Learning__\n",
    "Training data is unlabeled.\n",
    "\n",
    "Unsupervised learning algorithms:\n",
    "\n",
    "Clustering\n",
    "1. k-Means\n",
    "2. Hierarchical Cluster Analysis (HCA)\n",
    "3. Expectation Maximization\n",
    "\n",
    "Visualization and dimensionality reduction\n",
    "1. Principal Component Analysis (PCA)\n",
    "2. Kernel PCA\n",
    "3. Locally-Linear Embedding (LLE)\n",
    "4. t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "Association rule learning\n",
    "-  Apriori\n",
    "-  Eclat\n",
    "\n",
    "Visualization, dimensionality reduction, feature extraction. Reduce dimension of training data before feed to ML algorithm, benefit: run faster, less disk and memory usage, sometimes better performance.\n",
    "\n",
    "_Anomaly detection_\n",
    "\n",
    "_Association rule learning_\n",
    "<br>\n",
    "Goal: dig into large amounts of data and discover interesting relations\tbetween\tattributes.\n",
    "\n",
    "__Semisupervised Learning__\n",
    "<br>\n",
    "Algorithm deals with partially labeled training data (usually a\tlot of unlabeled data and a little bit of labeled data).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
